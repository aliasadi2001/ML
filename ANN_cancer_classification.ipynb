{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b37dd10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f74c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/cancer_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2227bd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>benign_0__mal_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness   \n",
       "0          17.99         10.38          122.80     1001.0          0.11840  \\\n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry   \n",
       "0             0.27760         0.30010              0.14710         0.2419  \\\n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area   \n",
       "0                   0.07871  ...          17.33           184.60      2019.0  \\\n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity   \n",
       "0             0.16220            0.66560           0.7119  \\\n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension   \n",
       "0                  0.2654          0.4601                  0.11890  \\\n",
       "1                  0.1860          0.2750                  0.08902   \n",
       "2                  0.2430          0.3613                  0.08758   \n",
       "3                  0.2575          0.6638                  0.17300   \n",
       "4                  0.1625          0.2364                  0.07678   \n",
       "..                    ...             ...                      ...   \n",
       "564                0.2216          0.2060                  0.07115   \n",
       "565                0.1628          0.2572                  0.06637   \n",
       "566                0.1418          0.2218                  0.07820   \n",
       "567                0.2650          0.4087                  0.12400   \n",
       "568                0.0000          0.2871                  0.07039   \n",
       "\n",
       "     benign_0__mal_1  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "..               ...  \n",
       "564                0  \n",
       "565                0  \n",
       "566                0  \n",
       "567                0  \n",
       "568                1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "206ce0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1',axis=1).values\n",
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d4eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "978e1ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55dea8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a2cd0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "904cc333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f70483",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34e8b2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 22:19:08.485576: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-29 22:19:08.565788: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-29 22:19:08.566838: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 22:19:09.925081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf91d487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccfd0b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d1cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(Dense(units=30,activation='relu'))\n",
    "\n",
    "model.add(Dense(units=15,activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b975376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 2s 23ms/step - loss: 0.6911 - val_loss: 0.6679\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6509 - val_loss: 0.6344\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6177 - val_loss: 0.6011\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5823 - val_loss: 0.5644\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5437 - val_loss: 0.5236\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5026 - val_loss: 0.4795\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4583 - val_loss: 0.4338\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4152 - val_loss: 0.3885\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3708 - val_loss: 0.3409\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3300 - val_loss: 0.3042\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2988 - val_loss: 0.2742\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2722 - val_loss: 0.2487\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2543 - val_loss: 0.2259\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2421 - val_loss: 0.2160\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2195 - val_loss: 0.1967\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2049 - val_loss: 0.1891\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1948 - val_loss: 0.1772\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1846 - val_loss: 0.1671\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1755 - val_loss: 0.1628\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1771 - val_loss: 0.1548\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1609 - val_loss: 0.1486\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1540 - val_loss: 0.1444\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1483 - val_loss: 0.1380\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1428 - val_loss: 0.1368\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1384 - val_loss: 0.1311\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1346 - val_loss: 0.1281\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1320 - val_loss: 0.1279\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1262 - val_loss: 0.1270\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1279 - val_loss: 0.1197\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1248 - val_loss: 0.1225\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1097 - val_loss: 0.1144\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1074 - val_loss: 0.1153\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1033 - val_loss: 0.1118\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1012 - val_loss: 0.1134\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0985 - val_loss: 0.1108\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0964 - val_loss: 0.1085\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0930 - val_loss: 0.1120\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0896 - val_loss: 0.1060\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0888 - val_loss: 0.1055\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0867 - val_loss: 0.1103\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0839 - val_loss: 0.1041\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0845 - val_loss: 0.1042\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0819 - val_loss: 0.1044\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0789 - val_loss: 0.1050\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0770 - val_loss: 0.1062\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0760 - val_loss: 0.1030\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0746 - val_loss: 0.1043\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0733 - val_loss: 0.1065\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0730 - val_loss: 0.1031\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0703 - val_loss: 0.1047\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0700 - val_loss: 0.1044\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0703 - val_loss: 0.1029\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0686 - val_loss: 0.1100\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0647 - val_loss: 0.1001\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0712 - val_loss: 0.1041\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0668 - val_loss: 0.1027\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0647 - val_loss: 0.1084\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0630 - val_loss: 0.1021\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0634 - val_loss: 0.1040\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0618 - val_loss: 0.1112\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0623 - val_loss: 0.1019\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0607 - val_loss: 0.1085\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0613 - val_loss: 0.1069\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0598 - val_loss: 0.1035\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0601 - val_loss: 0.1072\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0586 - val_loss: 0.1031\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0591 - val_loss: 0.1078\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0592 - val_loss: 0.1131\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0567 - val_loss: 0.1029\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0578 - val_loss: 0.1075\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0565 - val_loss: 0.1087\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0562 - val_loss: 0.1081\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0560 - val_loss: 0.1076\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0550 - val_loss: 0.1111\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0547 - val_loss: 0.1097\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0548 - val_loss: 0.1069\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0552 - val_loss: 0.1133\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0544 - val_loss: 0.1089\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0546 - val_loss: 0.1128\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0582 - val_loss: 0.1090\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0529 - val_loss: 0.1141\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0567 - val_loss: 0.1132\n",
      "Epoch 83/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0531 - val_loss: 0.1178\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0535 - val_loss: 0.1107\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0525 - val_loss: 0.1128\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0517 - val_loss: 0.1113\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0547 - val_loss: 0.1134\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0520 - val_loss: 0.1134\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0504 - val_loss: 0.1122\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0516 - val_loss: 0.1126\n",
      "Epoch 91/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0526 - val_loss: 0.1131\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0505 - val_loss: 0.1130\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0512 - val_loss: 0.1132\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0497 - val_loss: 0.1230\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0495 - val_loss: 0.1150\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0493 - val_loss: 0.1166\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0557 - val_loss: 0.1159\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0541 - val_loss: 0.1200\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0502 - val_loss: 0.1174\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0488 - val_loss: 0.1135\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0508 - val_loss: 0.1171\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0504 - val_loss: 0.1193\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0474 - val_loss: 0.1207\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0475 - val_loss: 0.1234\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0469 - val_loss: 0.1173\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0487 - val_loss: 0.1206\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0482 - val_loss: 0.1173\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0464 - val_loss: 0.1210\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0479 - val_loss: 0.1227\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0475 - val_loss: 0.1209\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0469 - val_loss: 0.1179\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0481 - val_loss: 0.1315\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0474 - val_loss: 0.1187\n",
      "Epoch 114/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0474 - val_loss: 0.1275\n",
      "Epoch 115/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0447 - val_loss: 0.1186\n",
      "Epoch 116/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0450 - val_loss: 0.1290\n",
      "Epoch 117/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0473 - val_loss: 0.1214\n",
      "Epoch 118/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0449 - val_loss: 0.1274\n",
      "Epoch 119/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0467 - val_loss: 0.1303\n",
      "Epoch 120/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0454 - val_loss: 0.1202\n",
      "Epoch 121/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0453 - val_loss: 0.1269\n",
      "Epoch 122/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0455 - val_loss: 0.1290\n",
      "Epoch 123/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0442 - val_loss: 0.1263\n",
      "Epoch 124/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0473 - val_loss: 0.1317\n",
      "Epoch 125/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0457 - val_loss: 0.1263\n",
      "Epoch 126/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0469 - val_loss: 0.1268\n",
      "Epoch 127/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0486 - val_loss: 0.1338\n",
      "Epoch 128/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0455 - val_loss: 0.1299\n",
      "Epoch 129/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0424 - val_loss: 0.1233\n",
      "Epoch 130/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0421 - val_loss: 0.1389\n",
      "Epoch 131/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0423 - val_loss: 0.1282\n",
      "Epoch 132/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0439 - val_loss: 0.1303\n",
      "Epoch 133/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0443 - val_loss: 0.1274\n",
      "Epoch 134/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0443 - val_loss: 0.1304\n",
      "Epoch 135/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0447 - val_loss: 0.1313\n",
      "Epoch 136/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0486 - val_loss: 0.1272\n",
      "Epoch 137/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0492 - val_loss: 0.1308\n",
      "Epoch 138/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0437 - val_loss: 0.1279\n",
      "Epoch 139/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0422 - val_loss: 0.1372\n",
      "Epoch 140/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0415 - val_loss: 0.1303\n",
      "Epoch 141/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0424 - val_loss: 0.1427\n",
      "Epoch 142/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0424 - val_loss: 0.1343\n",
      "Epoch 143/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0421 - val_loss: 0.1364\n",
      "Epoch 144/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0411 - val_loss: 0.1330\n",
      "Epoch 145/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0430 - val_loss: 0.1433\n",
      "Epoch 146/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0417 - val_loss: 0.1351\n",
      "Epoch 147/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0411 - val_loss: 0.1387\n",
      "Epoch 148/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0405 - val_loss: 0.1397\n",
      "Epoch 149/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0457 - val_loss: 0.1334\n",
      "Epoch 150/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0433 - val_loss: 0.1374\n",
      "Epoch 151/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0400 - val_loss: 0.1403\n",
      "Epoch 152/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0401 - val_loss: 0.1336\n",
      "Epoch 153/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0400 - val_loss: 0.1329\n",
      "Epoch 154/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0399 - val_loss: 0.1369\n",
      "Epoch 155/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0409 - val_loss: 0.1353\n",
      "Epoch 156/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.1410\n",
      "Epoch 157/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.1388\n",
      "Epoch 158/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0385 - val_loss: 0.1410\n",
      "Epoch 159/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0390 - val_loss: 0.1395\n",
      "Epoch 160/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.1403\n",
      "Epoch 161/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0392 - val_loss: 0.1449\n",
      "Epoch 162/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0406 - val_loss: 0.1352\n",
      "Epoch 163/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0401 - val_loss: 0.1476\n",
      "Epoch 164/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.1389\n",
      "Epoch 165/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0399 - val_loss: 0.1426\n",
      "Epoch 166/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.1334\n",
      "Epoch 167/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0390 - val_loss: 0.1527\n",
      "Epoch 168/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0380 - val_loss: 0.1389\n",
      "Epoch 169/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0375 - val_loss: 0.1455\n",
      "Epoch 170/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0401 - val_loss: 0.1369\n",
      "Epoch 171/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0426 - val_loss: 0.1437\n",
      "Epoch 172/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0423 - val_loss: 0.1417\n",
      "Epoch 173/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0432 - val_loss: 0.1457\n",
      "Epoch 174/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0407 - val_loss: 0.1397\n",
      "Epoch 175/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0418 - val_loss: 0.1475\n",
      "Epoch 176/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0399 - val_loss: 0.1425\n",
      "Epoch 177/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0371 - val_loss: 0.1425\n",
      "Epoch 178/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0362 - val_loss: 0.1456\n",
      "Epoch 179/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0366 - val_loss: 0.1517\n",
      "Epoch 180/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0364 - val_loss: 0.1518\n",
      "Epoch 181/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.1427\n",
      "Epoch 182/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0379 - val_loss: 0.1424\n",
      "Epoch 183/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0380 - val_loss: 0.1481\n",
      "Epoch 184/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0352 - val_loss: 0.1443\n",
      "Epoch 185/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0357 - val_loss: 0.1476\n",
      "Epoch 186/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0361 - val_loss: 0.1489\n",
      "Epoch 187/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0362 - val_loss: 0.1456\n",
      "Epoch 188/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0344 - val_loss: 0.1512\n",
      "Epoch 189/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0342 - val_loss: 0.1481\n",
      "Epoch 190/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0346 - val_loss: 0.1565\n",
      "Epoch 191/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0348 - val_loss: 0.1520\n",
      "Epoch 192/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0387 - val_loss: 0.1431\n",
      "Epoch 193/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0470 - val_loss: 0.1525\n",
      "Epoch 194/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0427 - val_loss: 0.1417\n",
      "Epoch 195/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0465 - val_loss: 0.1541\n",
      "Epoch 196/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0347 - val_loss: 0.1455\n",
      "Epoch 197/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0334 - val_loss: 0.1538\n",
      "Epoch 198/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0356 - val_loss: 0.1518\n",
      "Epoch 199/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0359 - val_loss: 0.1535\n",
      "Epoch 200/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0356 - val_loss: 0.1604\n",
      "Epoch 201/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0338 - val_loss: 0.1480\n",
      "Epoch 202/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0358 - val_loss: 0.1556\n",
      "Epoch 203/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0377 - val_loss: 0.1498\n",
      "Epoch 204/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0329 - val_loss: 0.1499\n",
      "Epoch 205/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0323 - val_loss: 0.1514\n",
      "Epoch 206/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0330 - val_loss: 0.1475\n",
      "Epoch 207/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0324 - val_loss: 0.1517\n",
      "Epoch 208/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0323 - val_loss: 0.1507\n",
      "Epoch 209/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0352 - val_loss: 0.1553\n",
      "Epoch 210/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0342 - val_loss: 0.1495\n",
      "Epoch 211/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0335 - val_loss: 0.1495\n",
      "Epoch 212/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0323 - val_loss: 0.1569\n",
      "Epoch 213/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0363 - val_loss: 0.1496\n",
      "Epoch 214/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0320 - val_loss: 0.1639\n",
      "Epoch 215/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0338 - val_loss: 0.1404\n",
      "Epoch 216/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0311 - val_loss: 0.1618\n",
      "Epoch 217/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0317 - val_loss: 0.1485\n",
      "Epoch 218/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0356 - val_loss: 0.1679\n",
      "Epoch 219/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0352 - val_loss: 0.1466\n",
      "Epoch 220/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0336 - val_loss: 0.1646\n",
      "Epoch 221/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0365 - val_loss: 0.1536\n",
      "Epoch 222/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0320 - val_loss: 0.1572\n",
      "Epoch 223/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0307 - val_loss: 0.1561\n",
      "Epoch 224/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0331 - val_loss: 0.1590\n",
      "Epoch 225/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0306 - val_loss: 0.1517\n",
      "Epoch 226/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0300 - val_loss: 0.1598\n",
      "Epoch 227/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0303 - val_loss: 0.1537\n",
      "Epoch 228/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0303 - val_loss: 0.1570\n",
      "Epoch 229/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0300 - val_loss: 0.1550\n",
      "Epoch 230/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0308 - val_loss: 0.1527\n",
      "Epoch 231/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0305 - val_loss: 0.1569\n",
      "Epoch 232/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0300 - val_loss: 0.1603\n",
      "Epoch 233/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0318 - val_loss: 0.1646\n",
      "Epoch 234/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0346 - val_loss: 0.1470\n",
      "Epoch 235/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0438 - val_loss: 0.1699\n",
      "Epoch 236/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0323 - val_loss: 0.1488\n",
      "Epoch 237/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0297 - val_loss: 0.1627\n",
      "Epoch 238/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0295 - val_loss: 0.1601\n",
      "Epoch 239/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0297 - val_loss: 0.1576\n",
      "Epoch 240/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0293 - val_loss: 0.1606\n",
      "Epoch 241/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0295 - val_loss: 0.1564\n",
      "Epoch 242/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0294 - val_loss: 0.1569\n",
      "Epoch 243/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0288 - val_loss: 0.1678\n",
      "Epoch 244/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0307 - val_loss: 0.1704\n",
      "Epoch 245/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0282 - val_loss: 0.1625\n",
      "Epoch 246/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0284 - val_loss: 0.1576\n",
      "Epoch 247/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0283 - val_loss: 0.1618\n",
      "Epoch 248/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0289 - val_loss: 0.1603\n",
      "Epoch 249/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0304 - val_loss: 0.1749\n",
      "Epoch 250/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0294 - val_loss: 0.1594\n",
      "Epoch 251/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0296 - val_loss: 0.1743\n",
      "Epoch 252/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0307 - val_loss: 0.1629\n",
      "Epoch 253/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0282 - val_loss: 0.1707\n",
      "Epoch 254/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.1580\n",
      "Epoch 255/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0275 - val_loss: 0.1656\n",
      "Epoch 256/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0283 - val_loss: 0.1661\n",
      "Epoch 257/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.1662\n",
      "Epoch 258/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.1619\n",
      "Epoch 259/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0273 - val_loss: 0.1671\n",
      "Epoch 260/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0284 - val_loss: 0.1633\n",
      "Epoch 261/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0303 - val_loss: 0.1711\n",
      "Epoch 262/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.1595\n",
      "Epoch 263/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.1699\n",
      "Epoch 264/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0280 - val_loss: 0.1686\n",
      "Epoch 265/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0261 - val_loss: 0.1683\n",
      "Epoch 266/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0262 - val_loss: 0.1715\n",
      "Epoch 267/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.1619\n",
      "Epoch 268/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.1740\n",
      "Epoch 269/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0257 - val_loss: 0.1649\n",
      "Epoch 270/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0283 - val_loss: 0.1572\n",
      "Epoch 271/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0279 - val_loss: 0.1719\n",
      "Epoch 272/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0257 - val_loss: 0.1740\n",
      "Epoch 273/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0253 - val_loss: 0.1650\n",
      "Epoch 274/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0262 - val_loss: 0.1785\n",
      "Epoch 275/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.1665\n",
      "Epoch 276/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0258 - val_loss: 0.1783\n",
      "Epoch 277/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0283 - val_loss: 0.1687\n",
      "Epoch 278/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0244 - val_loss: 0.1824\n",
      "Epoch 279/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0299 - val_loss: 0.1722\n",
      "Epoch 280/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0278 - val_loss: 0.1713\n",
      "Epoch 281/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0260 - val_loss: 0.1714\n",
      "Epoch 282/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0255 - val_loss: 0.1759\n",
      "Epoch 283/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0255 - val_loss: 0.1736\n",
      "Epoch 284/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.1710\n",
      "Epoch 285/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0239 - val_loss: 0.1825\n",
      "Epoch 286/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0252 - val_loss: 0.1731\n",
      "Epoch 287/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0275 - val_loss: 0.1683\n",
      "Epoch 288/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0251 - val_loss: 0.1874\n",
      "Epoch 289/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0253 - val_loss: 0.1750\n",
      "Epoch 290/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0247 - val_loss: 0.1772\n",
      "Epoch 291/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0252 - val_loss: 0.1835\n",
      "Epoch 292/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0244 - val_loss: 0.1642\n",
      "Epoch 293/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.1852\n",
      "Epoch 294/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.1736\n",
      "Epoch 295/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.1695\n",
      "Epoch 296/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0256 - val_loss: 0.1925\n",
      "Epoch 297/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0240 - val_loss: 0.1733\n",
      "Epoch 298/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.1747\n",
      "Epoch 299/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.1753\n",
      "Epoch 300/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0244 - val_loss: 0.1723\n",
      "Epoch 301/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.1868\n",
      "Epoch 302/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.1734\n",
      "Epoch 303/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.1814\n",
      "Epoch 304/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.1892\n",
      "Epoch 305/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0259 - val_loss: 0.1989\n",
      "Epoch 306/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0286 - val_loss: 0.1631\n",
      "Epoch 307/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0427 - val_loss: 0.2432\n",
      "Epoch 308/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0429 - val_loss: 0.1602\n",
      "Epoch 309/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0263 - val_loss: 0.1785\n",
      "Epoch 310/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.1739\n",
      "Epoch 311/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.1757\n",
      "Epoch 312/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.2012\n",
      "Epoch 313/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0234 - val_loss: 0.1729\n",
      "Epoch 314/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.1787\n",
      "Epoch 315/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0242 - val_loss: 0.1949\n",
      "Epoch 316/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.1688\n",
      "Epoch 317/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0262 - val_loss: 0.1755\n",
      "Epoch 318/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0252 - val_loss: 0.1850\n",
      "Epoch 319/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0250 - val_loss: 0.1872\n",
      "Epoch 320/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0231 - val_loss: 0.1668\n",
      "Epoch 321/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0222 - val_loss: 0.1844\n",
      "Epoch 322/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.1810\n",
      "Epoch 323/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.1759\n",
      "Epoch 324/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0240 - val_loss: 0.1878\n",
      "Epoch 325/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.1802\n",
      "Epoch 326/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.1783\n",
      "Epoch 327/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.1909\n",
      "Epoch 328/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 0.1771\n",
      "Epoch 329/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0237 - val_loss: 0.2087\n",
      "Epoch 330/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.1776\n",
      "Epoch 331/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.1841\n",
      "Epoch 332/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0204 - val_loss: 0.1814\n",
      "Epoch 333/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0206 - val_loss: 0.1841\n",
      "Epoch 334/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.1871\n",
      "Epoch 335/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0344 - val_loss: 0.1999\n",
      "Epoch 336/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0299 - val_loss: 0.1817\n",
      "Epoch 337/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.1929\n",
      "Epoch 338/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0219 - val_loss: 0.1693\n",
      "Epoch 339/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0219 - val_loss: 0.1909\n",
      "Epoch 340/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0196 - val_loss: 0.1815\n",
      "Epoch 341/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.1764\n",
      "Epoch 342/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.1962\n",
      "Epoch 343/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.1682\n",
      "Epoch 344/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0261 - val_loss: 0.2040\n",
      "Epoch 345/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.1793\n",
      "Epoch 346/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.2036\n",
      "Epoch 347/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.1813\n",
      "Epoch 348/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.2068\n",
      "Epoch 349/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.1798\n",
      "Epoch 350/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.1857\n",
      "Epoch 351/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0250 - val_loss: 0.1929\n",
      "Epoch 352/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0234 - val_loss: 0.1804\n",
      "Epoch 353/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0196 - val_loss: 0.1913\n",
      "Epoch 354/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.1866\n",
      "Epoch 355/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.1722\n",
      "Epoch 356/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.1998\n",
      "Epoch 357/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.1894\n",
      "Epoch 358/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0198 - val_loss: 0.1962\n",
      "Epoch 359/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.1865\n",
      "Epoch 360/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.1919\n",
      "Epoch 361/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0198 - val_loss: 0.1929\n",
      "Epoch 362/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.1925\n",
      "Epoch 363/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.1893\n",
      "Epoch 364/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.1866\n",
      "Epoch 365/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.1811\n",
      "Epoch 366/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.2063\n",
      "Epoch 367/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.1845\n",
      "Epoch 368/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0234 - val_loss: 0.2311\n",
      "Epoch 369/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.1724\n",
      "Epoch 370/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.2062\n",
      "Epoch 371/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.1939\n",
      "Epoch 372/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.1916\n",
      "Epoch 373/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0200 - val_loss: 0.1791\n",
      "Epoch 374/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.2037\n",
      "Epoch 375/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.1862\n",
      "Epoch 376/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.1873\n",
      "Epoch 377/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0175 - val_loss: 0.1878\n",
      "Epoch 378/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.1916\n",
      "Epoch 379/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.1893\n",
      "Epoch 380/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.1981\n",
      "Epoch 381/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.1766\n",
      "Epoch 382/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.2059\n",
      "Epoch 383/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.1871\n",
      "Epoch 384/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.2062\n",
      "Epoch 385/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0197 - val_loss: 0.1824\n",
      "Epoch 386/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.1985\n",
      "Epoch 387/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.1959\n",
      "Epoch 388/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.1881\n",
      "Epoch 389/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0206 - val_loss: 0.2023\n",
      "Epoch 390/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.2030\n",
      "Epoch 391/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.2041\n",
      "Epoch 392/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.2054\n",
      "Epoch 393/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.1939\n",
      "Epoch 394/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.2027\n",
      "Epoch 395/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0175 - val_loss: 0.1834\n",
      "Epoch 396/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.1994\n",
      "Epoch 397/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.1965\n",
      "Epoch 398/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.1883\n",
      "Epoch 399/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.2135\n",
      "Epoch 400/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.1889\n",
      "Epoch 401/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.2073\n",
      "Epoch 402/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.1932\n",
      "Epoch 403/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.1904\n",
      "Epoch 404/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.2259\n",
      "Epoch 405/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.1825\n",
      "Epoch 406/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.2033\n",
      "Epoch 407/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.2045\n",
      "Epoch 408/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.1851\n",
      "Epoch 409/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.2081\n",
      "Epoch 410/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.1928\n",
      "Epoch 411/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.2063\n",
      "Epoch 412/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.2273\n",
      "Epoch 413/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.1867\n",
      "Epoch 414/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.2202\n",
      "Epoch 415/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.2005\n",
      "Epoch 416/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.2044\n",
      "Epoch 417/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.2135\n",
      "Epoch 418/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.2035\n",
      "Epoch 419/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.2149\n",
      "Epoch 420/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0266 - val_loss: 0.2375\n",
      "Epoch 421/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0280 - val_loss: 0.1832\n",
      "Epoch 422/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.2260\n",
      "Epoch 423/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0160 - val_loss: 0.2008\n",
      "Epoch 424/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.2052\n",
      "Epoch 425/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.2047\n",
      "Epoch 426/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.2112\n",
      "Epoch 427/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.2130\n",
      "Epoch 428/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.1925\n",
      "Epoch 429/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.2185\n",
      "Epoch 430/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.2152\n",
      "Epoch 431/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.1977\n",
      "Epoch 432/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.2096\n",
      "Epoch 433/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.2150\n",
      "Epoch 434/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.2114\n",
      "Epoch 435/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.1987\n",
      "Epoch 436/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.2171\n",
      "Epoch 437/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.2007\n",
      "Epoch 438/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.2397\n",
      "Epoch 439/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.2020\n",
      "Epoch 440/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.2303\n",
      "Epoch 441/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.2085\n",
      "Epoch 442/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.2157\n",
      "Epoch 443/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.1964\n",
      "Epoch 444/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.2404\n",
      "Epoch 445/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.1983\n",
      "Epoch 446/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.2159\n",
      "Epoch 447/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.1986\n",
      "Epoch 448/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0242 - val_loss: 0.2720\n",
      "Epoch 449/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.1969\n",
      "Epoch 450/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.2267\n",
      "Epoch 451/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.1964\n",
      "Epoch 452/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.2210\n",
      "Epoch 453/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.2168\n",
      "Epoch 454/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.2045\n",
      "Epoch 455/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.2236\n",
      "Epoch 456/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.2187\n",
      "Epoch 457/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.2172\n",
      "Epoch 458/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.2354\n",
      "Epoch 459/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.2095\n",
      "Epoch 460/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.2344\n",
      "Epoch 461/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.2130\n",
      "Epoch 462/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.2203\n",
      "Epoch 463/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.2187\n",
      "Epoch 464/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.2215\n",
      "Epoch 465/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.2152\n",
      "Epoch 466/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.2325\n",
      "Epoch 467/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.2300\n",
      "Epoch 468/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.2003\n",
      "Epoch 469/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.3027\n",
      "Epoch 470/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0246 - val_loss: 0.2010\n",
      "Epoch 471/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.2585\n",
      "Epoch 472/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.1898\n",
      "Epoch 473/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.2397\n",
      "Epoch 474/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.2288\n",
      "Epoch 475/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.2144\n",
      "Epoch 476/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.2189\n",
      "Epoch 477/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.2213\n",
      "Epoch 478/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.2200\n",
      "Epoch 479/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.2227\n",
      "Epoch 480/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.2352\n",
      "Epoch 481/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.2423\n",
      "Epoch 482/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.2190\n",
      "Epoch 483/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.2274\n",
      "Epoch 484/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.2167\n",
      "Epoch 485/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.2413\n",
      "Epoch 486/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.2230\n",
      "Epoch 487/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.2216\n",
      "Epoch 488/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.2455\n",
      "Epoch 489/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.2161\n",
      "Epoch 490/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.2263\n",
      "Epoch 491/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.2238\n",
      "Epoch 492/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.2444\n",
      "Epoch 493/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.2327\n",
      "Epoch 494/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.2507\n",
      "Epoch 495/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.2262\n",
      "Epoch 496/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.2351\n",
      "Epoch 497/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.2293\n",
      "Epoch 498/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.2442\n",
      "Epoch 499/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.2305\n",
      "Epoch 500/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.2423\n",
      "Epoch 501/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.2404\n",
      "Epoch 502/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.2420\n",
      "Epoch 503/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.2540\n",
      "Epoch 504/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.2314\n",
      "Epoch 505/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.2444\n",
      "Epoch 506/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.2384\n",
      "Epoch 507/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.2327\n",
      "Epoch 508/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.2479\n",
      "Epoch 509/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.2342\n",
      "Epoch 510/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.2656\n",
      "Epoch 511/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.2318\n",
      "Epoch 512/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.2514\n",
      "Epoch 513/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.2395\n",
      "Epoch 514/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.2445\n",
      "Epoch 515/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.2301\n",
      "Epoch 516/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.2632\n",
      "Epoch 517/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.2348\n",
      "Epoch 518/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.2507\n",
      "Epoch 519/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.2423\n",
      "Epoch 520/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.2370\n",
      "Epoch 521/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.2492\n",
      "Epoch 522/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.2428\n",
      "Epoch 523/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.2614\n",
      "Epoch 524/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.2521\n",
      "Epoch 525/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.2596\n",
      "Epoch 526/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.2501\n",
      "Epoch 527/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.2430\n",
      "Epoch 528/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.2739\n",
      "Epoch 529/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.2415\n",
      "Epoch 530/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.2568\n",
      "Epoch 531/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.2748\n",
      "Epoch 532/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.2463\n",
      "Epoch 533/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.2599\n",
      "Epoch 534/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.2514\n",
      "Epoch 535/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.2555\n",
      "Epoch 536/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.2527\n",
      "Epoch 537/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.2747\n",
      "Epoch 538/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.2479\n",
      "Epoch 539/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.2629\n",
      "Epoch 540/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.2502\n",
      "Epoch 541/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.2787\n",
      "Epoch 542/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.2503\n",
      "Epoch 543/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.2693\n",
      "Epoch 544/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.2607\n",
      "Epoch 545/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.2606\n",
      "Epoch 546/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.2885\n",
      "Epoch 547/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.2621\n",
      "Epoch 548/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.2691\n",
      "Epoch 549/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.2713\n",
      "Epoch 550/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.2573\n",
      "Epoch 551/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.2854\n",
      "Epoch 552/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.2605\n",
      "Epoch 553/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.2667\n",
      "Epoch 554/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.2744\n",
      "Epoch 555/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.2630\n",
      "Epoch 556/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.2753\n",
      "Epoch 557/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.2558\n",
      "Epoch 558/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.2874\n",
      "Epoch 559/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.2536\n",
      "Epoch 560/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.2738\n",
      "Epoch 561/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.2950\n",
      "Epoch 562/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.2646\n",
      "Epoch 563/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.2891\n",
      "Epoch 564/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.2739\n",
      "Epoch 565/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.2795\n",
      "Epoch 566/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.2797\n",
      "Epoch 567/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.2846\n",
      "Epoch 568/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.2846\n",
      "Epoch 569/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.2643\n",
      "Epoch 570/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.2891\n",
      "Epoch 571/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.2840\n",
      "Epoch 572/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.2822\n",
      "Epoch 573/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.2763\n",
      "Epoch 574/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.2874\n",
      "Epoch 575/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.2991\n",
      "Epoch 576/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.2911\n",
      "Epoch 577/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.3116\n",
      "Epoch 578/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.2822\n",
      "Epoch 579/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.2874\n",
      "Epoch 580/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.2958\n",
      "Epoch 581/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.3045\n",
      "Epoch 582/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.2745\n",
      "Epoch 583/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.2941\n",
      "Epoch 584/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.2979\n",
      "Epoch 585/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.2878\n",
      "Epoch 586/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.2944\n",
      "Epoch 587/600\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0283 - val_loss: 0.4307\n",
      "Epoch 588/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0330 - val_loss: 0.2717\n",
      "Epoch 589/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.3025\n",
      "Epoch 590/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.2736\n",
      "Epoch 591/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.2817\n",
      "Epoch 592/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.2840\n",
      "Epoch 593/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.2992\n",
      "Epoch 594/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.2824\n",
      "Epoch 595/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.2944\n",
      "Epoch 596/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.2942\n",
      "Epoch 597/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.2986\n",
      "Epoch 598/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.2961\n",
      "Epoch 599/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.2951\n",
      "Epoch 600/600\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.3016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8fa98c19c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54e613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
