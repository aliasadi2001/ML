{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b37dd10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f74c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('EEG_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2227bd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>VideoID</th>\n",
       "      <th>Attention</th>\n",
       "      <th>Mediation</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>predefinedlabel</th>\n",
       "      <th>user-definedlabeln</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>25354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2012240.0</td>\n",
       "      <td>129350.0</td>\n",
       "      <td>61236.0</td>\n",
       "      <td>17084.0</td>\n",
       "      <td>11488.0</td>\n",
       "      <td>62462.0</td>\n",
       "      <td>49960.0</td>\n",
       "      <td>33932.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1005145.0</td>\n",
       "      <td>354328.0</td>\n",
       "      <td>37102.0</td>\n",
       "      <td>88881.0</td>\n",
       "      <td>45307.0</td>\n",
       "      <td>99603.0</td>\n",
       "      <td>44790.0</td>\n",
       "      <td>29749.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12806</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>127574.0</td>\n",
       "      <td>9951.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>21732.0</td>\n",
       "      <td>3872.0</td>\n",
       "      <td>39728.0</td>\n",
       "      <td>2598.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12807</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-275.0</td>\n",
       "      <td>323061.0</td>\n",
       "      <td>797464.0</td>\n",
       "      <td>153171.0</td>\n",
       "      <td>145805.0</td>\n",
       "      <td>39829.0</td>\n",
       "      <td>571280.0</td>\n",
       "      <td>36574.0</td>\n",
       "      <td>10010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12808</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-426.0</td>\n",
       "      <td>680989.0</td>\n",
       "      <td>154296.0</td>\n",
       "      <td>40068.0</td>\n",
       "      <td>39122.0</td>\n",
       "      <td>10966.0</td>\n",
       "      <td>26975.0</td>\n",
       "      <td>20427.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12809</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>366269.0</td>\n",
       "      <td>27346.0</td>\n",
       "      <td>11444.0</td>\n",
       "      <td>9932.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>12323.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12810</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>1164555.0</td>\n",
       "      <td>1184366.0</td>\n",
       "      <td>50014.0</td>\n",
       "      <td>124208.0</td>\n",
       "      <td>10634.0</td>\n",
       "      <td>445383.0</td>\n",
       "      <td>22133.0</td>\n",
       "      <td>4482.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12811 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SubjectID  VideoID  Attention  Mediation    Raw      Delta      Theta   \n",
       "0            0.0      0.0       56.0       43.0  278.0   301963.0    90612.0  \\\n",
       "1            0.0      0.0       40.0       35.0  -50.0    73787.0    28083.0   \n",
       "2            0.0      0.0       47.0       48.0  101.0   758353.0   383745.0   \n",
       "3            0.0      0.0       47.0       57.0   -5.0  2012240.0   129350.0   \n",
       "4            0.0      0.0       44.0       53.0   -8.0  1005145.0   354328.0   \n",
       "...          ...      ...        ...        ...    ...        ...        ...   \n",
       "12806        9.0      9.0       64.0       38.0  -39.0   127574.0     9951.0   \n",
       "12807        9.0      9.0       61.0       35.0 -275.0   323061.0   797464.0   \n",
       "12808        9.0      9.0       60.0       29.0 -426.0   680989.0   154296.0   \n",
       "12809        9.0      9.0       60.0       29.0  -84.0   366269.0    27346.0   \n",
       "12810        9.0      9.0       64.0       29.0  -49.0  1164555.0  1184366.0   \n",
       "\n",
       "         Alpha1    Alpha2    Beta1     Beta2   Gamma1   Gamma2   \n",
       "0       33735.0   23991.0  27946.0   45097.0  33228.0   8293.0  \\\n",
       "1        1439.0    2240.0   2746.0    3687.0   5293.0   2740.0   \n",
       "2      201999.0   62107.0  36293.0  130536.0  57243.0  25354.0   \n",
       "3       61236.0   17084.0  11488.0   62462.0  49960.0  33932.0   \n",
       "4       37102.0   88881.0  45307.0   99603.0  44790.0  29749.0   \n",
       "...         ...       ...      ...       ...      ...      ...   \n",
       "12806     709.0   21732.0   3872.0   39728.0   2598.0    960.0   \n",
       "12807  153171.0  145805.0  39829.0  571280.0  36574.0  10010.0   \n",
       "12808   40068.0   39122.0  10966.0   26975.0  20427.0   2024.0   \n",
       "12809   11444.0    9932.0   1939.0    3283.0  12323.0   1764.0   \n",
       "12810   50014.0  124208.0  10634.0  445383.0  22133.0   4482.0   \n",
       "\n",
       "       predefinedlabel  user-definedlabeln  \n",
       "0                  0.0                 0.0  \n",
       "1                  0.0                 0.0  \n",
       "2                  0.0                 0.0  \n",
       "3                  0.0                 0.0  \n",
       "4                  0.0                 0.0  \n",
       "...                ...                 ...  \n",
       "12806              1.0                 0.0  \n",
       "12807              1.0                 0.0  \n",
       "12808              1.0                 0.0  \n",
       "12809              1.0                 0.0  \n",
       "12810              1.0                 0.0  \n",
       "\n",
       "[12811 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c33f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('demographic_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6494e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject ID</th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>English</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject ID   age    ethnicity  gender\n",
       "0           0    25  Han Chinese       M\n",
       "1           1    24  Han Chinese       M\n",
       "2           2    31      English       M\n",
       "3           3    28  Han Chinese       F\n",
       "4           4    24      Bengali       M\n",
       "5           5    24  Han Chinese       M\n",
       "6           6    24  Han Chinese       M\n",
       "7           7    25  Han Chinese       M\n",
       "8           8    25  Han Chinese       M\n",
       "9           9    24  Han Chinese       F"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f9bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.rename(columns={'subject ID': 'SubjectID'}, inplace=True)\n",
    "\n",
    "data = df_2.merge(df, on='SubjectID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd688071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>VideoID</th>\n",
       "      <th>Attention</th>\n",
       "      <th>Mediation</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>predefinedlabel</th>\n",
       "      <th>user-definedlabeln</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>25354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2012240.0</td>\n",
       "      <td>129350.0</td>\n",
       "      <td>61236.0</td>\n",
       "      <td>17084.0</td>\n",
       "      <td>11488.0</td>\n",
       "      <td>62462.0</td>\n",
       "      <td>49960.0</td>\n",
       "      <td>33932.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1005145.0</td>\n",
       "      <td>354328.0</td>\n",
       "      <td>37102.0</td>\n",
       "      <td>88881.0</td>\n",
       "      <td>45307.0</td>\n",
       "      <td>99603.0</td>\n",
       "      <td>44790.0</td>\n",
       "      <td>29749.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12806</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>F</td>\n",
       "      <td>9.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>127574.0</td>\n",
       "      <td>9951.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>21732.0</td>\n",
       "      <td>3872.0</td>\n",
       "      <td>39728.0</td>\n",
       "      <td>2598.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12807</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>F</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-275.0</td>\n",
       "      <td>323061.0</td>\n",
       "      <td>797464.0</td>\n",
       "      <td>153171.0</td>\n",
       "      <td>145805.0</td>\n",
       "      <td>39829.0</td>\n",
       "      <td>571280.0</td>\n",
       "      <td>36574.0</td>\n",
       "      <td>10010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12808</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>F</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-426.0</td>\n",
       "      <td>680989.0</td>\n",
       "      <td>154296.0</td>\n",
       "      <td>40068.0</td>\n",
       "      <td>39122.0</td>\n",
       "      <td>10966.0</td>\n",
       "      <td>26975.0</td>\n",
       "      <td>20427.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12809</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>F</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>366269.0</td>\n",
       "      <td>27346.0</td>\n",
       "      <td>11444.0</td>\n",
       "      <td>9932.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>12323.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12810</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>F</td>\n",
       "      <td>9.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>1164555.0</td>\n",
       "      <td>1184366.0</td>\n",
       "      <td>50014.0</td>\n",
       "      <td>124208.0</td>\n",
       "      <td>10634.0</td>\n",
       "      <td>445383.0</td>\n",
       "      <td>22133.0</td>\n",
       "      <td>4482.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12811 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SubjectID   age    ethnicity  gender  VideoID  Attention  Mediation   \n",
       "0              0    25  Han Chinese       M      0.0       56.0       43.0  \\\n",
       "1              0    25  Han Chinese       M      0.0       40.0       35.0   \n",
       "2              0    25  Han Chinese       M      0.0       47.0       48.0   \n",
       "3              0    25  Han Chinese       M      0.0       47.0       57.0   \n",
       "4              0    25  Han Chinese       M      0.0       44.0       53.0   \n",
       "...          ...   ...          ...     ...      ...        ...        ...   \n",
       "12806          9    24  Han Chinese       F      9.0       64.0       38.0   \n",
       "12807          9    24  Han Chinese       F      9.0       61.0       35.0   \n",
       "12808          9    24  Han Chinese       F      9.0       60.0       29.0   \n",
       "12809          9    24  Han Chinese       F      9.0       60.0       29.0   \n",
       "12810          9    24  Han Chinese       F      9.0       64.0       29.0   \n",
       "\n",
       "         Raw      Delta      Theta    Alpha1    Alpha2    Beta1     Beta2   \n",
       "0      278.0   301963.0    90612.0   33735.0   23991.0  27946.0   45097.0  \\\n",
       "1      -50.0    73787.0    28083.0    1439.0    2240.0   2746.0    3687.0   \n",
       "2      101.0   758353.0   383745.0  201999.0   62107.0  36293.0  130536.0   \n",
       "3       -5.0  2012240.0   129350.0   61236.0   17084.0  11488.0   62462.0   \n",
       "4       -8.0  1005145.0   354328.0   37102.0   88881.0  45307.0   99603.0   \n",
       "...      ...        ...        ...       ...       ...      ...       ...   \n",
       "12806  -39.0   127574.0     9951.0     709.0   21732.0   3872.0   39728.0   \n",
       "12807 -275.0   323061.0   797464.0  153171.0  145805.0  39829.0  571280.0   \n",
       "12808 -426.0   680989.0   154296.0   40068.0   39122.0  10966.0   26975.0   \n",
       "12809  -84.0   366269.0    27346.0   11444.0    9932.0   1939.0    3283.0   \n",
       "12810  -49.0  1164555.0  1184366.0   50014.0  124208.0  10634.0  445383.0   \n",
       "\n",
       "        Gamma1   Gamma2  predefinedlabel  user-definedlabeln  \n",
       "0      33228.0   8293.0              0.0                 0.0  \n",
       "1       5293.0   2740.0              0.0                 0.0  \n",
       "2      57243.0  25354.0              0.0                 0.0  \n",
       "3      49960.0  33932.0              0.0                 0.0  \n",
       "4      44790.0  29749.0              0.0                 0.0  \n",
       "...        ...      ...              ...                 ...  \n",
       "12806   2598.0    960.0              1.0                 0.0  \n",
       "12807  36574.0  10010.0              1.0                 0.0  \n",
       "12808  20427.0   2024.0              1.0                 0.0  \n",
       "12809  12323.0   1764.0              1.0                 0.0  \n",
       "12810  22133.0   4482.0              1.0                 0.0  \n",
       "\n",
       "[12811 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad73b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['SubjectID','VideoID', ' gender'],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281ee7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>Attention</th>\n",
       "      <th>Mediation</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>predefinedlabel</th>\n",
       "      <th>user-definedlabeln</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>56.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>25354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>47.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2012240.0</td>\n",
       "      <td>129350.0</td>\n",
       "      <td>61236.0</td>\n",
       "      <td>17084.0</td>\n",
       "      <td>11488.0</td>\n",
       "      <td>62462.0</td>\n",
       "      <td>49960.0</td>\n",
       "      <td>33932.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>44.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1005145.0</td>\n",
       "      <td>354328.0</td>\n",
       "      <td>37102.0</td>\n",
       "      <td>88881.0</td>\n",
       "      <td>45307.0</td>\n",
       "      <td>99603.0</td>\n",
       "      <td>44790.0</td>\n",
       "      <td>29749.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12806</th>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>64.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>127574.0</td>\n",
       "      <td>9951.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>21732.0</td>\n",
       "      <td>3872.0</td>\n",
       "      <td>39728.0</td>\n",
       "      <td>2598.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12807</th>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>61.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-275.0</td>\n",
       "      <td>323061.0</td>\n",
       "      <td>797464.0</td>\n",
       "      <td>153171.0</td>\n",
       "      <td>145805.0</td>\n",
       "      <td>39829.0</td>\n",
       "      <td>571280.0</td>\n",
       "      <td>36574.0</td>\n",
       "      <td>10010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12808</th>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-426.0</td>\n",
       "      <td>680989.0</td>\n",
       "      <td>154296.0</td>\n",
       "      <td>40068.0</td>\n",
       "      <td>39122.0</td>\n",
       "      <td>10966.0</td>\n",
       "      <td>26975.0</td>\n",
       "      <td>20427.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12809</th>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>366269.0</td>\n",
       "      <td>27346.0</td>\n",
       "      <td>11444.0</td>\n",
       "      <td>9932.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>12323.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12810</th>\n",
       "      <td>24</td>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>64.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>1164555.0</td>\n",
       "      <td>1184366.0</td>\n",
       "      <td>50014.0</td>\n",
       "      <td>124208.0</td>\n",
       "      <td>10634.0</td>\n",
       "      <td>445383.0</td>\n",
       "      <td>22133.0</td>\n",
       "      <td>4482.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12811 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    ethnicity  Attention  Mediation    Raw      Delta      Theta   \n",
       "0        25  Han Chinese       56.0       43.0  278.0   301963.0    90612.0  \\\n",
       "1        25  Han Chinese       40.0       35.0  -50.0    73787.0    28083.0   \n",
       "2        25  Han Chinese       47.0       48.0  101.0   758353.0   383745.0   \n",
       "3        25  Han Chinese       47.0       57.0   -5.0  2012240.0   129350.0   \n",
       "4        25  Han Chinese       44.0       53.0   -8.0  1005145.0   354328.0   \n",
       "...     ...          ...        ...        ...    ...        ...        ...   \n",
       "12806    24  Han Chinese       64.0       38.0  -39.0   127574.0     9951.0   \n",
       "12807    24  Han Chinese       61.0       35.0 -275.0   323061.0   797464.0   \n",
       "12808    24  Han Chinese       60.0       29.0 -426.0   680989.0   154296.0   \n",
       "12809    24  Han Chinese       60.0       29.0  -84.0   366269.0    27346.0   \n",
       "12810    24  Han Chinese       64.0       29.0  -49.0  1164555.0  1184366.0   \n",
       "\n",
       "         Alpha1    Alpha2    Beta1     Beta2   Gamma1   Gamma2   \n",
       "0       33735.0   23991.0  27946.0   45097.0  33228.0   8293.0  \\\n",
       "1        1439.0    2240.0   2746.0    3687.0   5293.0   2740.0   \n",
       "2      201999.0   62107.0  36293.0  130536.0  57243.0  25354.0   \n",
       "3       61236.0   17084.0  11488.0   62462.0  49960.0  33932.0   \n",
       "4       37102.0   88881.0  45307.0   99603.0  44790.0  29749.0   \n",
       "...         ...       ...      ...       ...      ...      ...   \n",
       "12806     709.0   21732.0   3872.0   39728.0   2598.0    960.0   \n",
       "12807  153171.0  145805.0  39829.0  571280.0  36574.0  10010.0   \n",
       "12808   40068.0   39122.0  10966.0   26975.0  20427.0   2024.0   \n",
       "12809   11444.0    9932.0   1939.0    3283.0  12323.0   1764.0   \n",
       "12810   50014.0  124208.0  10634.0  445383.0  22133.0   4482.0   \n",
       "\n",
       "       predefinedlabel  user-definedlabeln  \n",
       "0                  0.0                 0.0  \n",
       "1                  0.0                 0.0  \n",
       "2                  0.0                 0.0  \n",
       "3                  0.0                 0.0  \n",
       "4                  0.0                 0.0  \n",
       "...                ...                 ...  \n",
       "12806              1.0                 0.0  \n",
       "12807              1.0                 0.0  \n",
       "12808              1.0                 0.0  \n",
       "12809              1.0                 0.0  \n",
       "12810              1.0                 0.0  \n",
       "\n",
       "[12811 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "206ce0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['user-definedlabeln'],axis = 1))\n",
    "y = np.array(df['user-definedlabeln'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89d4eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "978e1ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e93b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8516d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55dea8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a2cd0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "904cc333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4f70483",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34e8b2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 15:01:44.862915: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-05 15:01:44.947087: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-05 15:01:44.948092: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-05 15:01:46.423783: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf91d487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9608, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccfd0b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9d1cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(64, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e176169a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9608, 14)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8735c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b975376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "301/301 [==============================] - 6s 11ms/step - loss: 0.6931 - val_loss: 0.6929\n",
      "Epoch 2/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.6901 - val_loss: 0.6846\n",
      "Epoch 3/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.6673 - val_loss: 0.6510\n",
      "Epoch 4/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.6475 - val_loss: 0.6317\n",
      "Epoch 5/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.6332 - val_loss: 0.6309\n",
      "Epoch 6/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.6136 - val_loss: 0.6086\n",
      "Epoch 7/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.5971 - val_loss: 0.5907\n",
      "Epoch 8/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.5517 - val_loss: 0.5066\n",
      "Epoch 9/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.5057 - val_loss: 0.5084\n",
      "Epoch 10/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.4824 - val_loss: 0.4678\n",
      "Epoch 11/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.4658 - val_loss: 0.4321\n",
      "Epoch 12/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.4408 - val_loss: 0.4282\n",
      "Epoch 13/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.4251 - val_loss: 0.4046\n",
      "Epoch 14/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.4171 - val_loss: 0.4608\n",
      "Epoch 15/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3927 - val_loss: 0.3764\n",
      "Epoch 16/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3826 - val_loss: 0.5450\n",
      "Epoch 17/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.5666 - val_loss: 0.4953\n",
      "Epoch 18/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.4281 - val_loss: 0.3749\n",
      "Epoch 19/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3679 - val_loss: 0.3369\n",
      "Epoch 20/100\n",
      "301/301 [==============================] - 3s 11ms/step - loss: 0.3528 - val_loss: 0.3366\n",
      "Epoch 21/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3430 - val_loss: 0.3506\n",
      "Epoch 22/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3496 - val_loss: 0.3425\n",
      "Epoch 23/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3351 - val_loss: 0.3653\n",
      "Epoch 24/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3286 - val_loss: 0.3045\n",
      "Epoch 25/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3186 - val_loss: 0.2969\n",
      "Epoch 26/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3214 - val_loss: 0.3573\n",
      "Epoch 27/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3604 - val_loss: 0.3478\n",
      "Epoch 28/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3399 - val_loss: 0.3542\n",
      "Epoch 29/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3269 - val_loss: 0.2940\n",
      "Epoch 30/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3446 - val_loss: 0.2931\n",
      "Epoch 31/100\n",
      "301/301 [==============================] - 3s 11ms/step - loss: 0.3055 - val_loss: 0.3134\n",
      "Epoch 32/100\n",
      "301/301 [==============================] - 3s 11ms/step - loss: 0.3043 - val_loss: 0.2685\n",
      "Epoch 33/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.2943 - val_loss: 0.2743\n",
      "Epoch 34/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.2712 - val_loss: 0.2708\n",
      "Epoch 35/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.2874 - val_loss: 0.2919\n",
      "Epoch 36/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.2670 - val_loss: 0.2487\n",
      "Epoch 37/100\n",
      "301/301 [==============================] - 3s 11ms/step - loss: 0.2646 - val_loss: 0.2726\n",
      "Epoch 38/100\n",
      "301/301 [==============================] - 3s 11ms/step - loss: 0.2530 - val_loss: 0.2352\n",
      "Epoch 39/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.2602 - val_loss: 0.2298\n",
      "Epoch 40/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.2899 - val_loss: 0.2807\n",
      "Epoch 41/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.2620 - val_loss: 0.3566\n",
      "Epoch 42/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.2560 - val_loss: 0.2363\n",
      "Epoch 43/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.2398 - val_loss: 0.2090\n",
      "Epoch 44/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.2128 - val_loss: 0.2225\n",
      "Epoch 45/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.3149 - val_loss: 0.2136\n",
      "Epoch 46/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.2158 - val_loss: 0.3947\n",
      "Epoch 47/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.2099 - val_loss: 0.2690\n",
      "Epoch 48/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.2117 - val_loss: 0.2243\n",
      "Epoch 49/100\n",
      "301/301 [==============================] - 3s 11ms/step - loss: 0.1891 - val_loss: 0.1913\n",
      "Epoch 50/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1969 - val_loss: 0.1877\n",
      "Epoch 51/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1933 - val_loss: 0.2298\n",
      "Epoch 52/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1731 - val_loss: 0.2064\n",
      "Epoch 53/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1763 - val_loss: 0.4501\n",
      "Epoch 54/100\n",
      "301/301 [==============================] - 3s 11ms/step - loss: 0.2267 - val_loss: 0.1422\n",
      "Epoch 55/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1395 - val_loss: 0.2239\n",
      "Epoch 56/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1980 - val_loss: 0.1424\n",
      "Epoch 57/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1357 - val_loss: 0.1253\n",
      "Epoch 58/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1276 - val_loss: 0.1154\n",
      "Epoch 59/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1855 - val_loss: 0.1247\n",
      "Epoch 60/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1163 - val_loss: 0.1110\n",
      "Epoch 61/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1659 - val_loss: 0.1426\n",
      "Epoch 62/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1120 - val_loss: 0.0993\n",
      "Epoch 63/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1402 - val_loss: 0.1197\n",
      "Epoch 64/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1035 - val_loss: 0.0966\n",
      "Epoch 65/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1177 - val_loss: 0.2462\n",
      "Epoch 66/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0910 - val_loss: 0.0822\n",
      "Epoch 67/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1045 - val_loss: 0.1124\n",
      "Epoch 68/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1434 - val_loss: 0.0822\n",
      "Epoch 69/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0890 - val_loss: 0.1020\n",
      "Epoch 70/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0800 - val_loss: 0.0673\n",
      "Epoch 71/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1174 - val_loss: 0.0765\n",
      "Epoch 72/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0848 - val_loss: 0.0561\n",
      "Epoch 73/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0792 - val_loss: 0.0871\n",
      "Epoch 74/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0921 - val_loss: 0.0632\n",
      "Epoch 75/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0894 - val_loss: 0.1539\n",
      "Epoch 76/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0636 - val_loss: 0.0572\n",
      "Epoch 77/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0492 - val_loss: 0.0502\n",
      "Epoch 78/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0812 - val_loss: 0.0623\n",
      "Epoch 79/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1016 - val_loss: 0.0452\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0516 - val_loss: 0.1233\n",
      "Epoch 81/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0558 - val_loss: 0.0612\n",
      "Epoch 82/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0725 - val_loss: 0.0451\n",
      "Epoch 83/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0415 - val_loss: 0.0494\n",
      "Epoch 84/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1242 - val_loss: 0.0472\n",
      "Epoch 85/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0413 - val_loss: 0.0337\n",
      "Epoch 86/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0406 - val_loss: 0.0704\n",
      "Epoch 87/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0522 - val_loss: 0.0373\n",
      "Epoch 88/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0539 - val_loss: 0.0402\n",
      "Epoch 89/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0366 - val_loss: 0.0828\n",
      "Epoch 90/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0687 - val_loss: 0.0575\n",
      "Epoch 91/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0322 - val_loss: 0.0890\n",
      "Epoch 92/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.1015 - val_loss: 0.0331\n",
      "Epoch 93/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0411 - val_loss: 0.0265\n",
      "Epoch 94/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0341 - val_loss: 0.0314\n",
      "Epoch 95/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0459 - val_loss: 0.0292\n",
      "Epoch 96/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0542 - val_loss: 0.0699\n",
      "Epoch 97/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0318 - val_loss: 0.0236\n",
      "Epoch 98/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0508 - val_loss: 0.0363\n",
      "Epoch 99/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0270 - val_loss: 0.0307\n",
      "Epoch 100/100\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.0421 - val_loss: 0.0172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6dc4752ce0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=100,\n",
    "          validation_data=(X_test, y_test), verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54e613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190218df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d9ca994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3203, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c56d7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9608, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916dd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3db8f006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "163e0ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9943802684982829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming Y_train and Y_test are the true labels for training and test sets, respectively\n",
    "\n",
    "# Calculate accuracy for the training set\n",
    "train_accuracy = accuracy_score(y_test, np.round(y_pred))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training accuracy:\", train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d72852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22213291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
