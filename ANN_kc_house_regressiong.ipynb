{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf22410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a665802",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4bcbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf967dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f86337f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db2b6b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "886dc8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df['month'] = df['date'].apply(lambda date:date.month)\n",
    "df['year'] = df['date'].apply(lambda date:date.year)\n",
    "df = df.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf4ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('date',axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a33330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('zipcode',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74a7bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price',axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6bfa86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "230fc863",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde78f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0da798dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c83fd24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7452</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2290</td>\n",
       "      <td>6300</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2150</td>\n",
       "      <td>140</td>\n",
       "      <td>1921</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5917</td>\n",
       "      <td>-122.290</td>\n",
       "      <td>2390</td>\n",
       "      <td>6300</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20546</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1630</td>\n",
       "      <td>2520</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1630</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5493</td>\n",
       "      <td>-121.998</td>\n",
       "      <td>1630</td>\n",
       "      <td>3131</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21555</th>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2850</td>\n",
       "      <td>5577</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1950</td>\n",
       "      <td>900</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5252</td>\n",
       "      <td>-122.192</td>\n",
       "      <td>2850</td>\n",
       "      <td>5708</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1540</td>\n",
       "      <td>6632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1070</td>\n",
       "      <td>470</td>\n",
       "      <td>1959</td>\n",
       "      <td>0</td>\n",
       "      <td>47.4973</td>\n",
       "      <td>-122.252</td>\n",
       "      <td>2510</td>\n",
       "      <td>6618</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12625</th>\n",
       "      <td>4</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2010</td>\n",
       "      <td>7200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1010</td>\n",
       "      <td>1000</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5591</td>\n",
       "      <td>-122.267</td>\n",
       "      <td>2010</td>\n",
       "      <td>7200</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5695</th>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1350</td>\n",
       "      <td>7827</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1350</td>\n",
       "      <td>0</td>\n",
       "      <td>1968</td>\n",
       "      <td>0</td>\n",
       "      <td>47.3786</td>\n",
       "      <td>-122.219</td>\n",
       "      <td>1900</td>\n",
       "      <td>7827</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8006</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1430</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>930</td>\n",
       "      <td>500</td>\n",
       "      <td>1949</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5233</td>\n",
       "      <td>-122.284</td>\n",
       "      <td>1110</td>\n",
       "      <td>4000</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17745</th>\n",
       "      <td>2</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1800</td>\n",
       "      <td>7191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>990</td>\n",
       "      <td>810</td>\n",
       "      <td>1952</td>\n",
       "      <td>0</td>\n",
       "      <td>47.4828</td>\n",
       "      <td>-122.191</td>\n",
       "      <td>1940</td>\n",
       "      <td>7400</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17931</th>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1500</td>\n",
       "      <td>11233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>47.7279</td>\n",
       "      <td>-121.967</td>\n",
       "      <td>1580</td>\n",
       "      <td>14013</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13151</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1160</td>\n",
       "      <td>5038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>740</td>\n",
       "      <td>420</td>\n",
       "      <td>1942</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5304</td>\n",
       "      <td>-122.380</td>\n",
       "      <td>1160</td>\n",
       "      <td>5076</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15117 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view   \n",
       "7452          4       1.00         2290      6300     1.5           0     4  \\\n",
       "20546         3       2.25         1630      2520     2.0           0     0   \n",
       "21555         4       3.50         2850      5577     2.0           0     0   \n",
       "9795          3       1.75         1540      6632     1.0           0     0   \n",
       "12625         4       2.25         2010      7200     1.0           0     1   \n",
       "...         ...        ...          ...       ...     ...         ...   ...   \n",
       "5695          3       1.50         1350      7827     1.0           0     0   \n",
       "8006          2       1.00         1430      4000     1.0           0     0   \n",
       "17745         2       1.75         1800      7191     1.0           0     3   \n",
       "17931         3       2.00         1500     11233     1.0           0     0   \n",
       "13151         2       1.00         1160      5038     1.0           0     0   \n",
       "\n",
       "       condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated   \n",
       "7452           4      7        2150            140      1921             0  \\\n",
       "20546          3      7        1630              0      2005             0   \n",
       "21555          3      8        1950            900      2014             0   \n",
       "9795           3      7        1070            470      1959             0   \n",
       "12625          4      8        1010           1000      1950             0   \n",
       "...          ...    ...         ...            ...       ...           ...   \n",
       "5695           4      7        1350              0      1968             0   \n",
       "8006           3      7         930            500      1949             0   \n",
       "17745          4      7         990            810      1952             0   \n",
       "17931          3      7        1500              0      1987             0   \n",
       "13151          5      7         740            420      1942             0   \n",
       "\n",
       "           lat     long  sqft_living15  sqft_lot15  month  year  \n",
       "7452   47.5917 -122.290           2390        6300      9  2014  \n",
       "20546  47.5493 -121.998           1630        3131      6  2014  \n",
       "21555  47.5252 -122.192           2850        5708      5  2015  \n",
       "9795   47.4973 -122.252           2510        6618      2  2015  \n",
       "12625  47.5591 -122.267           2010        7200     10  2014  \n",
       "...        ...      ...            ...         ...    ...   ...  \n",
       "5695   47.3786 -122.219           1900        7827      8  2014  \n",
       "8006   47.5233 -122.284           1110        4000      7  2014  \n",
       "17745  47.4828 -122.191           1940        7400      4  2015  \n",
       "17931  47.7279 -121.967           1580       14013      4  2015  \n",
       "13151  47.5304 -122.380           1160        5076      1  2015  \n",
       "\n",
       "[15117 rows x 19 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58c7f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4afa4233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 20:19:21.909071: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-28 20:19:21.953394: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-28 20:19:21.953757: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-28 20:19:22.697240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d919316",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "457b46de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "60/60 [==============================] - 1s 5ms/step - loss: 430242365440.0000 - val_loss: 418921185280.0000\n",
      "Epoch 2/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 427290656768.0000 - val_loss: 402143739904.0000\n",
      "Epoch 3/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 272017489920.0000 - val_loss: 103886446592.0000\n",
      "Epoch 4/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 98924322816.0000 - val_loss: 92958269440.0000\n",
      "Epoch 5/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 93530603520.0000 - val_loss: 88514641920.0000\n",
      "Epoch 6/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 88420925440.0000 - val_loss: 83265708032.0000\n",
      "Epoch 7/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 82152382464.0000 - val_loss: 76474146816.0000\n",
      "Epoch 8/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 74361356288.0000 - val_loss: 67960406016.0000\n",
      "Epoch 9/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 65388154880.0000 - val_loss: 59339980800.0000\n",
      "Epoch 10/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 57621864448.0000 - val_loss: 53145522176.0000\n",
      "Epoch 11/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 52652261376.0000 - val_loss: 49632649216.0000\n",
      "Epoch 12/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 49460461568.0000 - val_loss: 47028633600.0000\n",
      "Epoch 13/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 47323308032.0000 - val_loss: 45521874944.0000\n",
      "Epoch 14/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 45770235904.0000 - val_loss: 43497029632.0000\n",
      "Epoch 15/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 43951550464.0000 - val_loss: 42114830336.0000\n",
      "Epoch 16/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 42755977216.0000 - val_loss: 40908881920.0000\n",
      "Epoch 17/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 41709154304.0000 - val_loss: 39869554688.0000\n",
      "Epoch 18/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 40784240640.0000 - val_loss: 38983462912.0000\n",
      "Epoch 19/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 39841767424.0000 - val_loss: 38161494016.0000\n",
      "Epoch 20/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 38957367296.0000 - val_loss: 37293912064.0000\n",
      "Epoch 21/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 38124572672.0000 - val_loss: 36625842176.0000\n",
      "Epoch 22/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 37441122304.0000 - val_loss: 35933335552.0000\n",
      "Epoch 23/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 36883922944.0000 - val_loss: 35366133760.0000\n",
      "Epoch 24/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 36366106624.0000 - val_loss: 34883215360.0000\n",
      "Epoch 25/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 35901726720.0000 - val_loss: 34715488256.0000\n",
      "Epoch 26/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 35423297536.0000 - val_loss: 34140608512.0000\n",
      "Epoch 27/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 35016544256.0000 - val_loss: 34005032960.0000\n",
      "Epoch 28/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 34858639360.0000 - val_loss: 33489844224.0000\n",
      "Epoch 29/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 34717917184.0000 - val_loss: 33945028608.0000\n",
      "Epoch 30/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 34616385536.0000 - val_loss: 33621856256.0000\n",
      "Epoch 31/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 34362089472.0000 - val_loss: 32991401984.0000\n",
      "Epoch 32/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 34108254208.0000 - val_loss: 32808513536.0000\n",
      "Epoch 33/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 34047467520.0000 - val_loss: 33787336704.0000\n",
      "Epoch 34/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 34138490880.0000 - val_loss: 32719509504.0000\n",
      "Epoch 35/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 33779208192.0000 - val_loss: 32596553728.0000\n",
      "Epoch 36/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 33961562112.0000 - val_loss: 32274874368.0000\n",
      "Epoch 37/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 33545435136.0000 - val_loss: 32156516352.0000\n",
      "Epoch 38/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 33535143936.0000 - val_loss: 31955654656.0000\n",
      "Epoch 39/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 33451696128.0000 - val_loss: 32378341376.0000\n",
      "Epoch 40/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 33504608256.0000 - val_loss: 32172216320.0000\n",
      "Epoch 41/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 33294583808.0000 - val_loss: 31568171008.0000\n",
      "Epoch 42/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 33190719488.0000 - val_loss: 31459168256.0000\n",
      "Epoch 43/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 33002596352.0000 - val_loss: 31504193536.0000\n",
      "Epoch 44/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 33217579008.0000 - val_loss: 31497981952.0000\n",
      "Epoch 45/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 34488082432.0000 - val_loss: 31361622016.0000\n",
      "Epoch 46/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32773466112.0000 - val_loss: 31738349568.0000\n",
      "Epoch 47/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32833331200.0000 - val_loss: 31308988416.0000\n",
      "Epoch 48/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32783683584.0000 - val_loss: 31048103936.0000\n",
      "Epoch 49/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32705845248.0000 - val_loss: 31099013120.0000\n",
      "Epoch 50/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32677728256.0000 - val_loss: 31169058816.0000\n",
      "Epoch 51/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32603936768.0000 - val_loss: 30866518016.0000\n",
      "Epoch 52/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32878594048.0000 - val_loss: 30739562496.0000\n",
      "Epoch 53/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32569559040.0000 - val_loss: 31104167936.0000\n",
      "Epoch 54/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32443287552.0000 - val_loss: 30596249600.0000\n",
      "Epoch 55/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32403251200.0000 - val_loss: 31576031232.0000\n",
      "Epoch 56/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32435150848.0000 - val_loss: 30559023104.0000\n",
      "Epoch 57/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32452786176.0000 - val_loss: 30508761088.0000\n",
      "Epoch 58/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32292970496.0000 - val_loss: 30442897408.0000\n",
      "Epoch 59/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32292173824.0000 - val_loss: 30910461952.0000\n",
      "Epoch 60/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32207941632.0000 - val_loss: 30571851776.0000\n",
      "Epoch 61/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32665800704.0000 - val_loss: 30282489856.0000\n",
      "Epoch 62/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32064677888.0000 - val_loss: 30194311168.0000\n",
      "Epoch 63/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32026161152.0000 - val_loss: 30243448832.0000\n",
      "Epoch 64/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32030889984.0000 - val_loss: 30153938944.0000\n",
      "Epoch 65/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32066641920.0000 - val_loss: 30163249152.0000\n",
      "Epoch 66/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32021299200.0000 - val_loss: 30116130816.0000\n",
      "Epoch 67/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31911512064.0000 - val_loss: 30203146240.0000\n",
      "Epoch 68/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31967764480.0000 - val_loss: 30044952576.0000\n",
      "Epoch 69/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 31920631808.0000 - val_loss: 29893502976.0000\n",
      "Epoch 70/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31856035840.0000 - val_loss: 29960710144.0000\n",
      "Epoch 71/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31932194816.0000 - val_loss: 29852485632.0000\n",
      "Epoch 72/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31735627776.0000 - val_loss: 29887451136.0000\n",
      "Epoch 73/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 32132939776.0000 - val_loss: 30213746688.0000\n",
      "Epoch 74/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31933861888.0000 - val_loss: 29712594944.0000\n",
      "Epoch 75/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31667943424.0000 - val_loss: 29703665664.0000\n",
      "Epoch 76/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 31722686464.0000 - val_loss: 30091710464.0000\n",
      "Epoch 77/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31479691264.0000 - val_loss: 29543921664.0000\n",
      "Epoch 78/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31489558528.0000 - val_loss: 29495091200.0000\n",
      "Epoch 79/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31555123200.0000 - val_loss: 29611560960.0000\n",
      "Epoch 80/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31985346560.0000 - val_loss: 29922318336.0000\n",
      "Epoch 81/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31550246912.0000 - val_loss: 29390612480.0000\n",
      "Epoch 82/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31346241536.0000 - val_loss: 29418065920.0000\n",
      "Epoch 83/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31413323776.0000 - val_loss: 29429823488.0000\n",
      "Epoch 84/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31435409408.0000 - val_loss: 29314871296.0000\n",
      "Epoch 85/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31430619136.0000 - val_loss: 29285455872.0000\n",
      "Epoch 86/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31270948864.0000 - val_loss: 29197021184.0000\n",
      "Epoch 87/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31197263872.0000 - val_loss: 29145808896.0000\n",
      "Epoch 88/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31530024960.0000 - val_loss: 29121806336.0000\n",
      "Epoch 89/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31215382528.0000 - val_loss: 29091049472.0000\n",
      "Epoch 90/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31192784896.0000 - val_loss: 29465026560.0000\n",
      "Epoch 91/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 31340187648.0000 - val_loss: 29067073536.0000\n",
      "Epoch 92/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 31085375488.0000 - val_loss: 29056110592.0000\n",
      "Epoch 93/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 30995124224.0000 - val_loss: 29158592512.0000\n",
      "Epoch 94/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 31160576000.0000 - val_loss: 29492529152.0000\n",
      "Epoch 95/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31841525760.0000 - val_loss: 29141002240.0000\n",
      "Epoch 96/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31394211840.0000 - val_loss: 29329285120.0000\n",
      "Epoch 97/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31093057536.0000 - val_loss: 28809095168.0000\n",
      "Epoch 98/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31108847616.0000 - val_loss: 29647386624.0000\n",
      "Epoch 99/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 31026030592.0000 - val_loss: 28806746112.0000\n",
      "Epoch 100/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 31071059968.0000 - val_loss: 28816115712.0000\n",
      "Epoch 101/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30888206336.0000 - val_loss: 29049112576.0000\n",
      "Epoch 102/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31032541184.0000 - val_loss: 28945917952.0000\n",
      "Epoch 103/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 30914191360.0000 - val_loss: 28670955520.0000\n",
      "Epoch 104/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30882949120.0000 - val_loss: 28654342144.0000\n",
      "Epoch 105/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31051776000.0000 - val_loss: 28475201536.0000\n",
      "Epoch 106/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30799675392.0000 - val_loss: 28589246464.0000\n",
      "Epoch 107/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 30790432768.0000 - val_loss: 28406730752.0000\n",
      "Epoch 108/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30682994688.0000 - val_loss: 29021523968.0000\n",
      "Epoch 109/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30804807680.0000 - val_loss: 28424347648.0000\n",
      "Epoch 110/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30654482432.0000 - val_loss: 28347609088.0000\n",
      "Epoch 111/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30784944128.0000 - val_loss: 28329846784.0000\n",
      "Epoch 112/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30710519808.0000 - val_loss: 28596658176.0000\n",
      "Epoch 113/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30588030976.0000 - val_loss: 28860928000.0000\n",
      "Epoch 114/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30778777600.0000 - val_loss: 28398508032.0000\n",
      "Epoch 115/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30594009088.0000 - val_loss: 28338288640.0000\n",
      "Epoch 116/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30524030976.0000 - val_loss: 28149911552.0000\n",
      "Epoch 117/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30510176256.0000 - val_loss: 28155820032.0000\n",
      "Epoch 118/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30516252672.0000 - val_loss: 28273383424.0000\n",
      "Epoch 119/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30480992256.0000 - val_loss: 28353742848.0000\n",
      "Epoch 120/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30592512000.0000 - val_loss: 28195151872.0000\n",
      "Epoch 121/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30465337344.0000 - val_loss: 28146221056.0000\n",
      "Epoch 122/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30498347008.0000 - val_loss: 28062101504.0000\n",
      "Epoch 123/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30346418176.0000 - val_loss: 28160489472.0000\n",
      "Epoch 124/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30377068544.0000 - val_loss: 28075526144.0000\n",
      "Epoch 125/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30390806528.0000 - val_loss: 28090136576.0000\n",
      "Epoch 126/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30331596800.0000 - val_loss: 27989243904.0000\n",
      "Epoch 127/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30273441792.0000 - val_loss: 27970529280.0000\n",
      "Epoch 128/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30365374464.0000 - val_loss: 28303165440.0000\n",
      "Epoch 129/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 31121121280.0000 - val_loss: 28131166208.0000\n",
      "Epoch 130/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30305705984.0000 - val_loss: 27780616192.0000\n",
      "Epoch 131/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 30498187264.0000 - val_loss: 28141299712.0000\n",
      "Epoch 132/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 30394380288.0000 - val_loss: 28259170304.0000\n",
      "Epoch 133/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30194382848.0000 - val_loss: 27780511744.0000\n",
      "Epoch 134/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30245158912.0000 - val_loss: 27913361408.0000\n",
      "Epoch 135/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30206810112.0000 - val_loss: 28177979392.0000\n",
      "Epoch 136/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30288543744.0000 - val_loss: 27852101632.0000\n",
      "Epoch 137/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 30178533376.0000 - val_loss: 27660644352.0000\n",
      "Epoch 138/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30113622016.0000 - val_loss: 28268148736.0000\n",
      "Epoch 139/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30334074880.0000 - val_loss: 27786395648.0000\n",
      "Epoch 140/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30098335744.0000 - val_loss: 27676682240.0000\n",
      "Epoch 141/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30088079360.0000 - val_loss: 27593902080.0000\n",
      "Epoch 142/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30193426432.0000 - val_loss: 27788574720.0000\n",
      "Epoch 143/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 30161434624.0000 - val_loss: 27397980160.0000\n",
      "Epoch 144/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29972355072.0000 - val_loss: 27492190208.0000\n",
      "Epoch 145/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29875791872.0000 - val_loss: 27558270976.0000\n",
      "Epoch 146/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29927530496.0000 - val_loss: 27431753728.0000\n",
      "Epoch 147/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29859717120.0000 - val_loss: 27377176576.0000\n",
      "Epoch 148/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29943400448.0000 - val_loss: 27289843712.0000\n",
      "Epoch 149/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29939259392.0000 - val_loss: 28070735872.0000\n",
      "Epoch 150/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29817573376.0000 - val_loss: 27405209600.0000\n",
      "Epoch 151/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29889636352.0000 - val_loss: 28130813952.0000\n",
      "Epoch 152/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29707829248.0000 - val_loss: 27704025088.0000\n",
      "Epoch 153/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29844017152.0000 - val_loss: 27222614016.0000\n",
      "Epoch 154/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29782067200.0000 - val_loss: 27074496512.0000\n",
      "Epoch 155/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29659904000.0000 - val_loss: 27164205056.0000\n",
      "Epoch 156/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29545566208.0000 - val_loss: 27003447296.0000\n",
      "Epoch 157/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29457844224.0000 - val_loss: 27210964992.0000\n",
      "Epoch 158/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29602084864.0000 - val_loss: 26978791424.0000\n",
      "Epoch 159/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29560510464.0000 - val_loss: 26941231104.0000\n",
      "Epoch 160/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29290059776.0000 - val_loss: 26770868224.0000\n",
      "Epoch 161/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29419264000.0000 - val_loss: 26854860800.0000\n",
      "Epoch 162/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29556105216.0000 - val_loss: 26723137536.0000\n",
      "Epoch 163/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29220024320.0000 - val_loss: 26865573888.0000\n",
      "Epoch 164/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29260605440.0000 - val_loss: 27014535168.0000\n",
      "Epoch 165/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29440495616.0000 - val_loss: 26525310976.0000\n",
      "Epoch 166/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29034993664.0000 - val_loss: 27006976000.0000\n",
      "Epoch 167/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29078360064.0000 - val_loss: 26531196928.0000\n",
      "Epoch 168/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 28894085120.0000 - val_loss: 26857125888.0000\n",
      "Epoch 169/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 28895645696.0000 - val_loss: 26413307904.0000\n",
      "Epoch 170/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 28835256320.0000 - val_loss: 28770422784.0000\n",
      "Epoch 171/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 29196652544.0000 - val_loss: 26188226560.0000\n",
      "Epoch 172/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 28820099072.0000 - val_loss: 26265856000.0000\n",
      "Epoch 173/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 28454852608.0000 - val_loss: 26340335616.0000\n",
      "Epoch 174/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 28357234688.0000 - val_loss: 25955072000.0000\n",
      "Epoch 175/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 28412532736.0000 - val_loss: 26103793664.0000\n",
      "Epoch 176/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 28535791616.0000 - val_loss: 25581109248.0000\n",
      "Epoch 177/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 28076912640.0000 - val_loss: 25728178176.0000\n",
      "Epoch 178/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 27819069440.0000 - val_loss: 25404583936.0000\n",
      "Epoch 179/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 27921215488.0000 - val_loss: 25190772736.0000\n",
      "Epoch 180/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 27637641216.0000 - val_loss: 25547593728.0000\n",
      "Epoch 181/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 27505160192.0000 - val_loss: 25094236160.0000\n",
      "Epoch 182/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 27279464448.0000 - val_loss: 24975169536.0000\n",
      "Epoch 183/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 27188930560.0000 - val_loss: 24714551296.0000\n",
      "Epoch 184/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 27114149888.0000 - val_loss: 24609777664.0000\n",
      "Epoch 185/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 26802423808.0000 - val_loss: 24377149440.0000\n",
      "Epoch 186/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 26672068608.0000 - val_loss: 24197296128.0000\n",
      "Epoch 187/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 26680682496.0000 - val_loss: 24020224000.0000\n",
      "Epoch 188/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 26381897728.0000 - val_loss: 23879399424.0000\n",
      "Epoch 189/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 26153293824.0000 - val_loss: 23792230400.0000\n",
      "Epoch 190/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 26022739968.0000 - val_loss: 23942977536.0000\n",
      "Epoch 191/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 25875808256.0000 - val_loss: 23577223168.0000\n",
      "Epoch 192/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 25853489152.0000 - val_loss: 23213637632.0000\n",
      "Epoch 193/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 25455755264.0000 - val_loss: 23610826752.0000\n",
      "Epoch 194/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 25562224640.0000 - val_loss: 25092853760.0000\n",
      "Epoch 195/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 25902690304.0000 - val_loss: 22829901824.0000\n",
      "Epoch 196/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 24982876160.0000 - val_loss: 24059191296.0000\n",
      "Epoch 197/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 25051150336.0000 - val_loss: 22629896192.0000\n",
      "Epoch 198/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 24765243392.0000 - val_loss: 22469967872.0000\n",
      "Epoch 199/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 24444233728.0000 - val_loss: 22282229760.0000\n",
      "Epoch 200/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 24487663616.0000 - val_loss: 22209595392.0000\n",
      "Epoch 201/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 24232452096.0000 - val_loss: 22332966912.0000\n",
      "Epoch 202/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 24056320000.0000 - val_loss: 22044299264.0000\n",
      "Epoch 203/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 23910381568.0000 - val_loss: 21854027776.0000\n",
      "Epoch 204/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 23640946688.0000 - val_loss: 21963284480.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 23605200896.0000 - val_loss: 21581473792.0000\n",
      "Epoch 206/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 23280295936.0000 - val_loss: 21713057792.0000\n",
      "Epoch 207/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 23619170304.0000 - val_loss: 21482090496.0000\n",
      "Epoch 208/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 23187812352.0000 - val_loss: 21136541696.0000\n",
      "Epoch 209/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 23004598272.0000 - val_loss: 21020723200.0000\n",
      "Epoch 210/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 22976253952.0000 - val_loss: 21539086336.0000\n",
      "Epoch 211/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 22761494528.0000 - val_loss: 20945190912.0000\n",
      "Epoch 212/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 22662430720.0000 - val_loss: 21129668608.0000\n",
      "Epoch 213/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 22550986752.0000 - val_loss: 20762939392.0000\n",
      "Epoch 214/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 22344312832.0000 - val_loss: 20862111744.0000\n",
      "Epoch 215/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 22444216320.0000 - val_loss: 20984918016.0000\n",
      "Epoch 216/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 22398865408.0000 - val_loss: 20722243584.0000\n",
      "Epoch 217/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 22105583616.0000 - val_loss: 20453193728.0000\n",
      "Epoch 218/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 22011559936.0000 - val_loss: 20769296384.0000\n",
      "Epoch 219/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 22081062912.0000 - val_loss: 20394110976.0000\n",
      "Epoch 220/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 21840658432.0000 - val_loss: 20391032832.0000\n",
      "Epoch 221/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 21682145280.0000 - val_loss: 21011838976.0000\n",
      "Epoch 222/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 21854019584.0000 - val_loss: 20060534784.0000\n",
      "Epoch 223/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 21710196736.0000 - val_loss: 20198000640.0000\n",
      "Epoch 224/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 21681321984.0000 - val_loss: 20182278144.0000\n",
      "Epoch 225/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 21681401856.0000 - val_loss: 20234520576.0000\n",
      "Epoch 226/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 21344460800.0000 - val_loss: 20146915328.0000\n",
      "Epoch 227/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 21572691968.0000 - val_loss: 19938234368.0000\n",
      "Epoch 228/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 21479663616.0000 - val_loss: 20009170944.0000\n",
      "Epoch 229/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 21147385856.0000 - val_loss: 19787120640.0000\n",
      "Epoch 230/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 21025984512.0000 - val_loss: 19946491904.0000\n",
      "Epoch 231/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 21163401216.0000 - val_loss: 19926970368.0000\n",
      "Epoch 232/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 21101088768.0000 - val_loss: 19882008576.0000\n",
      "Epoch 233/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 21049534464.0000 - val_loss: 20122568704.0000\n",
      "Epoch 234/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20922015744.0000 - val_loss: 19874183168.0000\n",
      "Epoch 235/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20887146496.0000 - val_loss: 19674142720.0000\n",
      "Epoch 236/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20776912896.0000 - val_loss: 19538978816.0000\n",
      "Epoch 237/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20613109760.0000 - val_loss: 19522009088.0000\n",
      "Epoch 238/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20598556672.0000 - val_loss: 19492024320.0000\n",
      "Epoch 239/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20604168192.0000 - val_loss: 19735246848.0000\n",
      "Epoch 240/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20567156736.0000 - val_loss: 19561293824.0000\n",
      "Epoch 241/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20617250816.0000 - val_loss: 19539867648.0000\n",
      "Epoch 242/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 20533745664.0000 - val_loss: 19291998208.0000\n",
      "Epoch 243/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20370407424.0000 - val_loss: 19755110400.0000\n",
      "Epoch 244/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20717281280.0000 - val_loss: 19459487744.0000\n",
      "Epoch 245/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20322748416.0000 - val_loss: 19058636800.0000\n",
      "Epoch 246/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20356608000.0000 - val_loss: 19034503168.0000\n",
      "Epoch 247/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20302063616.0000 - val_loss: 19444824064.0000\n",
      "Epoch 248/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20627480576.0000 - val_loss: 19131582464.0000\n",
      "Epoch 249/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20132636672.0000 - val_loss: 19108057088.0000\n",
      "Epoch 250/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20253927424.0000 - val_loss: 19168720896.0000\n",
      "Epoch 251/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20178028544.0000 - val_loss: 19161755648.0000\n",
      "Epoch 252/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19985922048.0000 - val_loss: 18863529984.0000\n",
      "Epoch 253/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20083197952.0000 - val_loss: 19961114624.0000\n",
      "Epoch 254/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20061358080.0000 - val_loss: 18877712384.0000\n",
      "Epoch 255/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19815792640.0000 - val_loss: 18843559936.0000\n",
      "Epoch 256/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20103546880.0000 - val_loss: 19501199360.0000\n",
      "Epoch 257/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20240216064.0000 - val_loss: 19045779456.0000\n",
      "Epoch 258/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19644624896.0000 - val_loss: 18780012544.0000\n",
      "Epoch 259/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19617644544.0000 - val_loss: 19069868032.0000\n",
      "Epoch 260/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19767715840.0000 - val_loss: 18976319488.0000\n",
      "Epoch 261/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 19720493056.0000 - val_loss: 19332886528.0000\n",
      "Epoch 262/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19804467200.0000 - val_loss: 18776150016.0000\n",
      "Epoch 263/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19416719360.0000 - val_loss: 19008634880.0000\n",
      "Epoch 264/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19517769728.0000 - val_loss: 18826127360.0000\n",
      "Epoch 265/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20415389696.0000 - val_loss: 18660691968.0000\n",
      "Epoch 266/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19481784320.0000 - val_loss: 18601408512.0000\n",
      "Epoch 267/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19403726848.0000 - val_loss: 19494490112.0000\n",
      "Epoch 268/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19356104704.0000 - val_loss: 18725386240.0000\n",
      "Epoch 269/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19364413440.0000 - val_loss: 18870079488.0000\n",
      "Epoch 270/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19473969152.0000 - val_loss: 18570061824.0000\n",
      "Epoch 271/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19322388480.0000 - val_loss: 19006384128.0000\n",
      "Epoch 272/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 19402432512.0000 - val_loss: 18847412224.0000\n",
      "Epoch 273/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20097716224.0000 - val_loss: 18859319296.0000\n",
      "Epoch 274/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19314649088.0000 - val_loss: 18779508736.0000\n",
      "Epoch 275/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19271501824.0000 - val_loss: 18517798912.0000\n",
      "Epoch 276/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19143436288.0000 - val_loss: 19204317184.0000\n",
      "Epoch 277/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19303245824.0000 - val_loss: 18470703104.0000\n",
      "Epoch 278/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19250878464.0000 - val_loss: 18483636224.0000\n",
      "Epoch 279/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19069122560.0000 - val_loss: 18372255744.0000\n",
      "Epoch 280/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19138017280.0000 - val_loss: 18628407296.0000\n",
      "Epoch 281/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18989056000.0000 - val_loss: 18471479296.0000\n",
      "Epoch 282/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19059828736.0000 - val_loss: 18584131584.0000\n",
      "Epoch 283/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19093553152.0000 - val_loss: 18565593088.0000\n",
      "Epoch 284/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19293497344.0000 - val_loss: 18524895232.0000\n",
      "Epoch 285/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18848135168.0000 - val_loss: 19909392384.0000\n",
      "Epoch 286/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 20538355712.0000 - val_loss: 18585655296.0000\n",
      "Epoch 287/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19288508416.0000 - val_loss: 19213877248.0000\n",
      "Epoch 288/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19439665152.0000 - val_loss: 19254845440.0000\n",
      "Epoch 289/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19034277888.0000 - val_loss: 18460778496.0000\n",
      "Epoch 290/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18841669632.0000 - val_loss: 18819303424.0000\n",
      "Epoch 291/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19242756096.0000 - val_loss: 18664380416.0000\n",
      "Epoch 292/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18928629760.0000 - val_loss: 18416240640.0000\n",
      "Epoch 293/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18914793472.0000 - val_loss: 18630199296.0000\n",
      "Epoch 294/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18801545216.0000 - val_loss: 18350876672.0000\n",
      "Epoch 295/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18779488256.0000 - val_loss: 18368108544.0000\n",
      "Epoch 296/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18781556736.0000 - val_loss: 18276530176.0000\n",
      "Epoch 297/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 18605828096.0000 - val_loss: 18268823552.0000\n",
      "Epoch 298/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18610814976.0000 - val_loss: 18732165120.0000\n",
      "Epoch 299/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18628421632.0000 - val_loss: 18283532288.0000\n",
      "Epoch 300/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18614775808.0000 - val_loss: 18456832000.0000\n",
      "Epoch 301/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18644072448.0000 - val_loss: 18233157632.0000\n",
      "Epoch 302/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18533134336.0000 - val_loss: 18407432192.0000\n",
      "Epoch 303/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18717642752.0000 - val_loss: 18187343872.0000\n",
      "Epoch 304/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18779807744.0000 - val_loss: 18163382272.0000\n",
      "Epoch 305/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18656581632.0000 - val_loss: 18213666816.0000\n",
      "Epoch 306/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18553096192.0000 - val_loss: 18538745856.0000\n",
      "Epoch 307/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18664613888.0000 - val_loss: 18339012608.0000\n",
      "Epoch 308/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18721167360.0000 - val_loss: 18270273536.0000\n",
      "Epoch 309/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18966087680.0000 - val_loss: 18413885440.0000\n",
      "Epoch 310/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 18561495040.0000 - val_loss: 18525902848.0000\n",
      "Epoch 311/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18441345024.0000 - val_loss: 18172004352.0000\n",
      "Epoch 312/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18425817088.0000 - val_loss: 18281519104.0000\n",
      "Epoch 313/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18576797696.0000 - val_loss: 18275387392.0000\n",
      "Epoch 314/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18272421888.0000 - val_loss: 18418018304.0000\n",
      "Epoch 315/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18775746560.0000 - val_loss: 18503260160.0000\n",
      "Epoch 316/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18210842624.0000 - val_loss: 19137853440.0000\n",
      "Epoch 317/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18430011392.0000 - val_loss: 18396459008.0000\n",
      "Epoch 318/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18281031680.0000 - val_loss: 18371864576.0000\n",
      "Epoch 319/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18252177408.0000 - val_loss: 18844004352.0000\n",
      "Epoch 320/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18581682176.0000 - val_loss: 18479341568.0000\n",
      "Epoch 321/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18476824576.0000 - val_loss: 18179895296.0000\n",
      "Epoch 322/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18295416832.0000 - val_loss: 18737741824.0000\n",
      "Epoch 323/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18379898880.0000 - val_loss: 18232479744.0000\n",
      "Epoch 324/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18270316544.0000 - val_loss: 18063644672.0000\n",
      "Epoch 325/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18369386496.0000 - val_loss: 18995879936.0000\n",
      "Epoch 326/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 19396151296.0000 - val_loss: 18235944960.0000\n",
      "Epoch 327/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18439380992.0000 - val_loss: 18435561472.0000\n",
      "Epoch 328/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18129172480.0000 - val_loss: 18423412736.0000\n",
      "Epoch 329/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18028357632.0000 - val_loss: 18492379136.0000\n",
      "Epoch 330/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18632183808.0000 - val_loss: 18137761792.0000\n",
      "Epoch 331/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18112806912.0000 - val_loss: 18278885376.0000\n",
      "Epoch 332/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18190063616.0000 - val_loss: 18186049536.0000\n",
      "Epoch 333/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18295621632.0000 - val_loss: 18213097472.0000\n",
      "Epoch 334/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17996001280.0000 - val_loss: 18591039488.0000\n",
      "Epoch 335/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18015006720.0000 - val_loss: 18324473856.0000\n",
      "Epoch 336/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 18035355648.0000 - val_loss: 18237925376.0000\n",
      "Epoch 337/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 18192590848.0000 - val_loss: 18447286272.0000\n",
      "Epoch 338/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18220234752.0000 - val_loss: 18488776704.0000\n",
      "Epoch 339/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18028593152.0000 - val_loss: 18108557312.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17868419072.0000 - val_loss: 18099030016.0000\n",
      "Epoch 341/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17942099968.0000 - val_loss: 18059038720.0000\n",
      "Epoch 342/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17775597568.0000 - val_loss: 18063423488.0000\n",
      "Epoch 343/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17859059712.0000 - val_loss: 18581706752.0000\n",
      "Epoch 344/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18234664960.0000 - val_loss: 18164314112.0000\n",
      "Epoch 345/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17740578816.0000 - val_loss: 18688169984.0000\n",
      "Epoch 346/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 18103578624.0000 - val_loss: 18458662912.0000\n",
      "Epoch 347/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17988214784.0000 - val_loss: 18019528704.0000\n",
      "Epoch 348/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17758199808.0000 - val_loss: 17927090176.0000\n",
      "Epoch 349/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17778116608.0000 - val_loss: 18049503232.0000\n",
      "Epoch 350/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17596307456.0000 - val_loss: 18147823616.0000\n",
      "Epoch 351/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17650712576.0000 - val_loss: 18155745280.0000\n",
      "Epoch 352/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17982720000.0000 - val_loss: 17929635840.0000\n",
      "Epoch 353/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17642420224.0000 - val_loss: 18047602688.0000\n",
      "Epoch 354/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17661679616.0000 - val_loss: 18336266240.0000\n",
      "Epoch 355/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17708234752.0000 - val_loss: 18130929664.0000\n",
      "Epoch 356/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17616797696.0000 - val_loss: 17964599296.0000\n",
      "Epoch 357/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17657753600.0000 - val_loss: 18598350848.0000\n",
      "Epoch 358/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17455241216.0000 - val_loss: 17926846464.0000\n",
      "Epoch 359/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17468469248.0000 - val_loss: 18163132416.0000\n",
      "Epoch 360/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17564096512.0000 - val_loss: 17979205632.0000\n",
      "Epoch 361/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17741293568.0000 - val_loss: 17956235264.0000\n",
      "Epoch 362/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17412481024.0000 - val_loss: 17866082304.0000\n",
      "Epoch 363/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17421176832.0000 - val_loss: 17839976448.0000\n",
      "Epoch 364/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17419304960.0000 - val_loss: 18084085760.0000\n",
      "Epoch 365/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 17477203968.0000 - val_loss: 19251775488.0000\n",
      "Epoch 366/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17512036352.0000 - val_loss: 17819658240.0000\n",
      "Epoch 367/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17397637120.0000 - val_loss: 18251257856.0000\n",
      "Epoch 368/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17392683008.0000 - val_loss: 18659479552.0000\n",
      "Epoch 369/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17583343616.0000 - val_loss: 18066595840.0000\n",
      "Epoch 370/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17678622720.0000 - val_loss: 18197270528.0000\n",
      "Epoch 371/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17249380352.0000 - val_loss: 18058309632.0000\n",
      "Epoch 372/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17236342784.0000 - val_loss: 18023073792.0000\n",
      "Epoch 373/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17520572416.0000 - val_loss: 17934649344.0000\n",
      "Epoch 374/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 17125094400.0000 - val_loss: 17842577408.0000\n",
      "Epoch 375/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17320110080.0000 - val_loss: 20661843968.0000\n",
      "Epoch 376/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 22983651328.0000 - val_loss: 18547867648.0000\n",
      "Epoch 377/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17509009408.0000 - val_loss: 18046914560.0000\n",
      "Epoch 378/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17379440640.0000 - val_loss: 18075631616.0000\n",
      "Epoch 379/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17448777728.0000 - val_loss: 17796786176.0000\n",
      "Epoch 380/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17125453824.0000 - val_loss: 17884184576.0000\n",
      "Epoch 381/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17144658944.0000 - val_loss: 17696571392.0000\n",
      "Epoch 382/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17017732096.0000 - val_loss: 18098501632.0000\n",
      "Epoch 383/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17115889664.0000 - val_loss: 17854068736.0000\n",
      "Epoch 384/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17434707968.0000 - val_loss: 18292582400.0000\n",
      "Epoch 385/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17104873472.0000 - val_loss: 18133882880.0000\n",
      "Epoch 386/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17092464640.0000 - val_loss: 18183294976.0000\n",
      "Epoch 387/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17053649920.0000 - val_loss: 17635862528.0000\n",
      "Epoch 388/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17182969856.0000 - val_loss: 17654290432.0000\n",
      "Epoch 389/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17119407104.0000 - val_loss: 18632439808.0000\n",
      "Epoch 390/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17245960192.0000 - val_loss: 18222559232.0000\n",
      "Epoch 391/400\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 16899832832.0000 - val_loss: 17820061696.0000\n",
      "Epoch 392/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17001780224.0000 - val_loss: 17821411328.0000\n",
      "Epoch 393/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17169088512.0000 - val_loss: 17581008896.0000\n",
      "Epoch 394/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17084238848.0000 - val_loss: 17672556544.0000\n",
      "Epoch 395/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 17101892608.0000 - val_loss: 17765937152.0000\n",
      "Epoch 396/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 16876299264.0000 - val_loss: 17635272704.0000\n",
      "Epoch 397/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 16804237312.0000 - val_loss: 17510494208.0000\n",
      "Epoch 398/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 16966050816.0000 - val_loss: 17737621504.0000\n",
      "Epoch 399/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 16906958848.0000 - val_loss: 17549649920.0000\n",
      "Epoch 400/400\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 16782284800.0000 - val_loss: 17466314752.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fddc439b010>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train.values,\n",
    "          validation_data=(X_test,y_test.values),\n",
    "          batch_size=256,epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a0f395f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 707us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b93d68a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cadacd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d51b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=(np.array(y_test)).reshape(6480,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa66129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=np.sqrt((1-np.power((np.sum(np.abs(y_pred-y_test))/np.sum(np.abs(y_test))),2)))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5861881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.90911966803499"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e5c0fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 888us/step - loss: 17466314752.0000\n",
      "Mean Squared Error:  17466314752.0\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test, y_test)\n",
    "print('Mean Squared Error: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee288da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
